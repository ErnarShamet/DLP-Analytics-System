# DLP Analytics System: Интеллектуальная Платформа Предотвращения Утечек Данных

## 🚀 Описание проекта

**DLP Analytics System** — это не просто система предотвращения утечек данных (DLP). Это комплексная платформа, спроектированная для проактивной защиты информации с использованием передовых аналитических инструментов и мощи машинного обучения. Наша цель — предоставить организациям глубокое понимание информационных потоков, автоматизировать выявление угроз и обеспечить эффективное реагирование на инциденты.

Система сочетает в себе классические DLP-механизмы с инновационными подходами, такими как **пользовательская и поведенческая аналитика (UEBA)** для выявления аномалий и **автоматическая классификация контента** для точного определения чувствительности данных.

## ✨ Ключевые возможности

*   🛡️ **Гибкое Управление Политиками DLP:** Создавайте, настраивайте и мгновенно применяйте детализированные политики безопасности, адаптированные под нужды вашего бизнеса.
*   📡 **Мониторинг и Оповещения в Реальном Времени:** Мгновенно получайте уведомления о потенциальных нарушениях политик и подозрительной активности.
*   🕵️ **Комплексное Управление Инцидентами:** Централизованное отслеживание, расследование и реагирование на инциденты с полным аудитом действий.
*   📊 **Продвинутая Аналитика и Визуализация:** Интерактивные дашборды и отчеты для глубокого анализа событий DLP, выявления трендов и оценки эффективности политик.
*   🤖 **Интеллектуальная Аналитика (ML):**
    *   **UEBA (User and Entity Behavior Analytics):** Обнаружение аномального поведения пользователей и сущностей, которое может указывать на внутренние угрозы или скомпрометированные учетные записи.
    *   **Классификация Контента:** Автоматическое определение уровня чувствительности данных (конфиденциально, для внутреннего использования, публично и т.д.) на основе их содержания.
*   👤 **Управление Доступом на Основе Ролей (RBAC):** Четкое разграничение прав доступа к функциям и данным системы для обеспечения безопасности и соответствия требованиям.
*   📈 **Комплексный Мониторинг Системы:** Сбор и визуализация метрик производительности и состояния всех компонентов системы с помощью Prometheus и Grafana.
*   ☁️ **Готовность к Облаку:** Архитектура, разработанная с учетом масштабируемости и развертывания в Kubernetes.

## 🛠️ Технологический стек

Система построена на современном и надежном технологическом стеке, обеспечивающем высокую производительность, масштабируемость и удобство разработки:

*   **Бэкенд:**
    *   **Среда исполнения:** Node.js
    *   **Фреймворк:** Express.js
    *   **База данных:** MongoDB (с Mongoose ODM)
    *   **Кэширование и очереди:** Redis
*   **Фронтенд:**
    *   **Библиотека:** React (с TypeScript)
    *   **UI Компоненты:** Material-UI
    *   **Стилизация:** Tailwind CSS
    *   **Управление состоянием:** Redux Toolkit
    *   **Работа с данными:** React Query
*   **ML-движок (Аналитическое ядро):**
    *   **Язык:** Python
    *   **Фреймворк API:** Flask (или FastAPI)
    *   **Библиотеки ML:** Scikit-learn, Pandas, NumPy (и другие по мере необходимости: TensorFlow, PyTorch)
*   **Оркестрация и Контейнеризация:**
    *   **Локальная разработка:** Docker, Docker Compose
    *   **Production:** Kubernetes
*   **Мониторинг и Визуализация:**
    *   **Сбор метрик:** Prometheus
    *   **Дашборды:** Grafana

## 🏗️ Структура проекта

Проект имеет модульную структуру, разделенную на три основных компонента: `backend`, `frontend` и `ml-engine`, а также конфигурации для `kubernetes` и `monitoring`. Детальное описание каждого файла и папки представлено в дереве выше.

## 🚀 Установка и Запуск

### Локальная разработка (с Docker Compose)

1.  **Клонируйте репозиторий:**
    ```bash
    git clone <URL_репозитория>
    cd DLP-Analytics-System
    ```
2.  **Настройте переменные окружения:**
    Скопируйте `.env.example` в `.env` и заполните необходимые значения:
    ```bash
    cp .env.example .env
    # Отредактируйте .env файл (например, MONGO_URI, JWT_SECRET и т.д.)
    ```
3.  **Соберите и запустите контейнеры:**
    ```bash
    docker-compose up --build -d
    ```
    *   Фронтенд будет доступен по адресу: `http://localhost:3000` (или порт, указанный в `FRONTEND_PORT`)
    *   Бэкенд API будет доступен по адресу: `http://localhost:5001` (или порт, указанный в `PORT`)
    *   ML-движок API будет доступен по адресу: `http://localhost:5002` (или порт, указанный в `ML_ENGINE_PORT`)
    *   Prometheus: `http://localhost:9090`
    *   Grafana: `http://localhost:3001` (или порт, указанный в `GRAFANA_PORT`)

4.  **(Только для ML-движка, если модели не встроены)** Обучите модели, если это необходимо:
    ```bash
    docker-compose exec ml-engine python scripts/train_model.py
    ```

### Развертывание в Kubernetes

Детальные инструкции по развертыванию в Kubernetes будут добавлены позже. Основные шаги включают:

1.  Сборку Docker-образов и их загрузку в репозиторий образов (например, Docker Hub, GCR, ECR).
2.  Настройку `configmap.yaml` и `secrets.yaml` под ваше окружение.
3.  Применение манифестов из папки `kubernetes/` с помощью `kubectl apply -f <file_name>.yaml -n dlp-ns`.

## 📈 Мониторинг

Система интегрирована с Prometheus для сбора метрик и Grafana для их визуализации.

*   **Prometheus:** Собирает метрики с `backend` и `ml-engine`. Доступен по `http://localhost:9090` (при локальном запуске).
*   **Grafana:** Предоставляет дашборды для визуализации состояния системы. Доступна по `http://localhost:3001` (логин/пароль по умолчанию или из `.env`). Преднастроенные дашборды и источник данных Prometheus автоматически провижинятся.

## 🗺️ Дальнейшие шаги и Дорожная карта (Примеры)

*   [ ] Расширение набора ML моделей для более точной классификации и UEBA.
*   [ ] Интеграция с SIEM системами.
*   [ ] Поддержка анализа структурированных данных (базы данных, CSV).
*   [ ] Разработка агентов для конечных точек.
*   [ ] Расширенные возможности отчетности и аудита.
*   [ ] Внедрение поддержки Optical Character Recognition (OCR) для анализа изображений.

##🤝 Вклад

Мы приветствуем вклад в развитие проекта! Пожалуйста, ознакомьтесь с `CONTRIBUTING.md` (будет добавлен позже) для получения информации о том, как вы можете помочь.

---

Надеюсь, такое описание делает проект более интересным и понятным!